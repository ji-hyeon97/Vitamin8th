{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70c0302",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e332edb",
   "metadata": {},
   "source": [
    "### 1. Label Encoding \n",
    "embark_town 변수를 레이블 인코딩하고,  <p>\n",
    "레이블 인코딩한 값을 기존 데이터 프레임에 'embark_town_labels'라는 열로 추가해보세요.<p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe6b5877",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "titanic = sns.load_dataset('titanic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd18025",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fcc85942",
   "metadata": {},
   "source": [
    "### 2. 결측값/중복값 처리 \n",
    "타민은 한국환경공단에서 발표한 미세먼지 관련 자료를 분석하려고 데이터를 다운로드받았습니다. <p>\n",
    "하지만 데이터에 결측값이 많아 이를 우선 조정하려고 합니다. <p>\n",
    "    타민과 함께 데이터를 처리해주세요! ('finedust.csv' 파일을 활용하세요)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82280951",
   "metadata": {},
   "source": [
    "#### 2.1. \n",
    "파일을 불러와 컬럼 별 결측치 개수를 구하세요. <p>\n",
    "(이 파일은 공공기관 파일로, 인코딩이 utf-8이 아닌 cp949로 되어있습니다! <p>\n",
    "    read_csv 사용 시 오류가 발생하면 pd.read_csv('경로\\\\finedust.csv', engine='python')으로 불러와주세요! <p>\n",
    "        기타 문제 발생 시 바로 문의주세요!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7bb8985",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6ce89ffb",
   "metadata": {},
   "source": [
    "#### 2.2\n",
    "타민은 '분석할만한 데이터가 6개 미만인 데이터는 제외해도 좋을 것 같은데?'라며 해당 데이터를 삭제하려 합니다.<p>\n",
    "적합한 코드를 알려주세요. (tip: dropna, tresh 활용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c68cdb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3d26b8c2",
   "metadata": {},
   "source": [
    "#### 2.3\n",
    "데이터를 살펴보던 타민은 아래와 같이 데이터를 조작해서 다음 분석 단계로 넘어가려 합니다. <p>아래 순서와 조건에 맞게 데이터를 수정해보세요(inplace=True).\n",
    "\n",
    "    1) '도로명', '시작점', '종점' 데이터를 제외하고 분석할거야 (컬럼 기준 tresh 사용하기)\n",
    "    2) '측정 시간', '지역', '지역명'의 공백은 바로 위 데이터로 대체할래 (hint: method='ffill')\n",
    "    3) '측정 일자'와 '지역명', '재비산먼지'가 중복되는 데이터는 가장 첫번째 케이스를 제외하고 제외해야지 (hint:drop_duplicates, keep='First')\n",
    "    4) '기온', '습도'의 결측값은 각 열의 평균값으로 채울래\n",
    "    5) '오염범례'의 결측값은 최빈값으로 대체하자(hint: value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca981ec0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "433a279d",
   "metadata": {},
   "source": [
    "#### 2.4 \n",
    "타민처럼 데이터를 처리했을 때 생길 수 있는 문제점은 무엇일까요? 여러분이라면 이 데이터를 어떻게 처리할 것인가요? <p>\n",
    "    자유롭게 생각해봅시다:)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd4023f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1603ce6a",
   "metadata": {},
   "source": [
    "### 3. 불균형 데이터\n",
    "1번 문제에서 만든 embark_town_labels 열을 추가한 titanic 데이터프레임을 사용하여,  <p>\n",
    "X는 pclass, embark_town_labels, y는 survived로 X와 y값을 설정하세요.  <p>\n",
    "위 X,y에 대해 over sampling 기법 중 하나를 선택하여 전처리를 진행하고 어떻게 데이터가 변화하였는지 살펴보세요.  <p>\n",
    "(hint: shape, value_counts 등을 통해 샘플링 전후 데이터 개수의 변화를 알 수 있습니다.)<p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791bc6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede7e132",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c18f721e",
   "metadata": {},
   "source": [
    "### 4. Feature Scaling\n",
    "학구열로 불타오르는 타민이는 정규 세션에서 배운 Feature Scaling 내용을 스스로 공부해보려고 한다.<p>\n",
    "최근 영화에 관심에 생긴 타민이는 네이버 영화와 왓챠를 자주 이용한다.<p>\n",
    "영화 평점에 굉장히 민감한 타민이는 최근 유행하는 영화 50편의 평점 데이터를 네이버와 왓챠피디아에서 가져왔고, <p>\n",
    "이를 통해 두 영화 평점 사이트의 데이터를 비교해보고자 한다.<p>\n",
    "고민에 빠진 타민이를 도와주자!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7ad951",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "naver_data = pd.read_csv('naver_movie_rating.csv')\n",
    "watcha_data = pd.read_csv('watcha_movie_rating.csv')\n",
    "\n",
    "# 완성되지 않은 부분을 채우세요!\n",
    "\n",
    "# naver_data에서 movie_rating 컬럼만 추출하여 1차원 numpy array로 변환해준다.\n",
    "naver_rating = \n",
    "\n",
    "# watcha_data에서 movie_rating 컬럼만 추출하여 1차원 numpy array로 변환해준다.\n",
    "watcha_rating = "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef97ed52",
   "metadata": {},
   "source": [
    "<p style=\"line-height:200%\">네이버에서는 영화 평점을 <b>최소 0점부터 최대 10점까지</b> 부여할 수 있고, 왓챠에서는 영화 평점을 <b>최소 0점부터 최대 5점까지</b> 부여할 수 있다. 즉, 네이버와 왓챠의 평점은 <b>각각 10점, 5점이 만점</b>이고, <b>최저점으로 0점</b>이 존재할 수 있다.</p>\n",
    "<br>\n",
    "<p style=\"line-height:200%\">이를 고려하여 각 사이트의 평점 데이터를 <b>0부터 1까지의 범위</b>로 스케일링한 결과를 구해보자.</p>\n",
    "<br>\n",
    "<p style=\"line-height:200%\"><b>※ MinMaxScaler 사용</b></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56662b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 완성되지 않은 부분을 채우세요!\n",
    "\n",
    "## 미완성 부분 ##\n",
    "\n",
    "naver_rating_scaled = \n",
    "\n",
    "print('스케일링 된 네이버 영화 평점 데이터')\n",
    "print('최저 평점: ', np.round(naver_rating_scaled.min(),2))\n",
    "print('최고 평점: ', np.round(naver_rating_scaled.max(),2))\n",
    "print('평균 평점: ', np.round(naver_rating_scaled.mean(),2))\n",
    "print('평점 분산: ', np.round(naver_rating_scaled.var(),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a801d609",
   "metadata": {},
   "source": [
    "<p style=\"line-height:200%\"><b>아래의 결과처럼 나오도록 한다.</b></p>\n",
    "<br>\n",
    "스케일링 된 네이버 영화 평점 데이터<br>\n",
    "최저 평점:  0.57<br>\n",
    "최고 평점:  0.93<br>\n",
    "평균 평점:  0.82<br>\n",
    "평점 분산:  0.01<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76d5fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 완성되지 않은 부분을 채우세요!\n",
    "\n",
    "## 미완성 부분 ##\n",
    "\n",
    "watcha_rating_scaled = \n",
    "\n",
    "print('스케일링 된 왓챠 영화 평점 데이터')\n",
    "print('최저 평점: ', np.round(watcha_rating_scaled.min(),2))\n",
    "print('최고 평점: ', np.round(watcha_rating_scaled.max(),2))\n",
    "print('평균 평점: ', np.round(watcha_rating_scaled.mean(),2))\n",
    "print('평점 분산: ', np.round(watcha_rating_scaled.var(),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7520ce4c",
   "metadata": {},
   "source": [
    "<p style=\"line-height:200%\"><b>아래의 결과처럼 나오도록 한다.</b></p>\n",
    "<br>\n",
    "스케일링 된 왓챠 영화 평점 데이터<br>\n",
    "최저 평점:  0.5<br>\n",
    "최고 평점:  0.84<br>\n",
    "평균 평점:  0.71<br>\n",
    "평점 분산:  0.01<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b6693dc",
   "metadata": {},
   "source": [
    "<p style=\"line-height:200%\">만약 네이버와 왓챠 평점의 <b>만점이 모두 10점</b>이고, 조사한 왓챠 평점 데이터가 5점 만점이 아닌 <b>10점 만점일 때의 데이터</b>라고 가정해 보자.</p>\n",
    "<br>\n",
    "<p>이 때 왓챠 사이트의 평점 데이터를 <b>0부터 1까지의 범위</b>로 스케일링한 결과를 각각 구해보자.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e7f6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 완성되지 않은 부분을 채우세요!\n",
    "\n",
    "## 미완성 부분 ##\n",
    "\n",
    "watcha_rating_scaled = \n",
    "\n",
    "print('스케일링 된 10점 만점의 왓챠 영화 평점 데이터')\n",
    "print('최저 평점: ', np.round(watcha_rating_scaled.min(),2))\n",
    "print('최고 평점: ', np.round(watcha_rating_scaled.max(),2))\n",
    "print('평균 평점: ', np.round(watcha_rating_scaled.mean(),2))\n",
    "print('평점 분산: ', np.round(watcha_rating_scaled.var(),2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
